{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-04-01T22:29:40.370074Z",
     "start_time": "2025-04-01T22:29:37.942494Z"
    }
   },
   "source": [
    "from torch import nn\n",
    "import sys\n",
    "from src.API.AI_API_Call import openai_topic_generation, gemini_generation, openai_generation, \\\n",
    "    gemini_embedding_generation, words_to_pos_types\n",
    "from src.API.text_classifier import TextData\n",
    "from src.API.constant import AI, HUMAN, OPENAI_MODEL_NAME, GEMINI_MODEL_NAME\n",
    "from src.API.machine_learning import k_mean_cluster_fit_predict, load_kmeans_model, \\\n",
    "    hierarchical_cluster_fit_predict, load_hierarchical_model, load_autoencoders, \\\n",
    "    autoencoder_classify_text, evaluate_sequence, load_transition_matrix, Autoencoder"
   ],
   "execution_count": 1,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-01T22:29:42.138451Z",
     "start_time": "2025-04-01T22:29:42.136005Z"
    }
   },
   "cell_type": "code",
   "source": [
    "EMBEDDING_CLASSIFICATION = 'embedding_classification'\n",
    "k_mean_file_path = './model_file/kmean.pkl'\n",
    "hierarchical_file_path = './model_file/hierarchical.pkl'\n",
    "autoencoder_file_path = './model_file/autoencoders.pth'\n",
    "human_transition_matrix_file_path = './model_file/human_matrix.pkl'\n",
    "ai_transition_matrix_file_path = './model_file/AI_matrix.pkl'"
   ],
   "id": "eca215cc1408f37",
   "execution_count": 2,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-01T22:29:42.454762Z",
     "start_time": "2025-04-01T22:29:42.451614Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class KMeanModel:\n",
    "    def __init__(self, model, feature_array, cluster_majority):\n",
    "        self.model = model\n",
    "        self.feature_array = feature_array\n",
    "        self.cluster_majority = cluster_majority\n",
    "\n",
    "\n",
    "class HierarchicalModel:\n",
    "    def __init__(self, agg_cluster, feature_array, cluster_majority, cluster_centroid):\n",
    "        self.agg_cluster = agg_cluster\n",
    "        self.feature_array = feature_array\n",
    "        self.cluster_majority = cluster_majority\n",
    "        self.cluster_centroid = cluster_centroid\n",
    "\n",
    "\n",
    "class AutoencoderModel:\n",
    "    def __init__(self, encoder, optimizer, criterion, input_dim, latent_dim):\n",
    "        self.encoder = encoder\n",
    "        self.optimizer = optimizer\n",
    "        self.criterion = criterion\n",
    "        self.input_dim = input_dim\n",
    "        self.latent_dim = latent_dim"
   ],
   "id": "faa8cfec71d1c612",
   "execution_count": 3,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-01T22:29:42.713776Z",
     "start_time": "2025-04-01T22:29:42.710521Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def load_models(\n",
    "        kmeans_model_file_path: str,\n",
    "        hierarchical_model_file_path: str,\n",
    "        autoencoder_file_path: str,\n",
    "        human_transition_matrix_file_path: str,\n",
    "        ai_transition_matrix_file_path: str):\n",
    "    \"\"\"\n",
    "    Load the KMeans, Hierarchical, Autoencoder, and transition matrix models.\n",
    "\n",
    "    \"\"\"\n",
    "    # Load KMeans model\n",
    "    kmeans_model_data = load_kmeans_model(kmeans_model_file_path)\n",
    "    kmeans_model = KMeanModel(kmeans_model_data['kmeans'], kmeans_model_data['feature_array'],\n",
    "                              kmeans_model_data['cluster_majorities'])\n",
    "    # Load Hierarchical model\n",
    "    hierarchical_model = load_hierarchical_model(hierarchical_model_file_path)\n",
    "    hierarchical_model = HierarchicalModel(hierarchical_model['agg_cluster'], hierarchical_model['feature_array'],\n",
    "                                           hierarchical_model['cluster_majorities'],\n",
    "                                           hierarchical_model['cluster_centroids'])\n",
    "\n",
    "    # Load Autoencoder model\n",
    "    # Load the trained autoencoders\n",
    "    h_encoder, AI_encoder, h_optimizer, AI_optimizer, metadata = load_autoencoders(autoencoder_file_path)\n",
    "\n",
    "    # Extract input and latent dimensions\n",
    "    input_dim = metadata[\"input_dim\"]\n",
    "    latent_dim = metadata[\"latent_dim\"]\n",
    "\n",
    "    # Define loss functions\n",
    "    h_criterion = nn.MSELoss()\n",
    "    AI_criterion = nn.MSELoss()\n",
    "    # Create Autoencoder model instances\n",
    "    h_autoencoder = AutoencoderModel(h_encoder, h_optimizer, h_criterion, input_dim, latent_dim)\n",
    "    AI_autoencoder = AutoencoderModel(AI_encoder, AI_optimizer, AI_criterion, input_dim, latent_dim)\n",
    "\n",
    "    # Load transition matrix\n",
    "    human_transition_matrix = load_transition_matrix(human_transition_matrix_file_path)\n",
    "    ai_transition_matrix = load_transition_matrix(ai_transition_matrix_file_path)\n",
    "\n",
    "    return kmeans_model, hierarchical_model, h_autoencoder, AI_autoencoder, human_transition_matrix, \\\n",
    "        ai_transition_matrix"
   ],
   "id": "2d19c87aaa36eae1",
   "execution_count": 4,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-01T22:29:42.921667Z",
     "start_time": "2025-04-01T22:29:42.918465Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def handle_user_input(user_input: str = None):\n",
    "    \"\"\"\n",
    "    Handles user input for the AI API call.\n",
    "    \"\"\"\n",
    "    # Get user input if not provided\n",
    "    if user_input is None:\n",
    "        user_input = input(\"Enter your article you would like to test: \")\n",
    "\n",
    "    # Generate the topic using the OpenAI model\n",
    "    topic = openai_topic_generation(user_input)\n",
    "    print(f\"Topic generated: {topic}\")\n",
    "    # Generate the article using the Gemini model\n",
    "    gemini_response = gemini_generation(topic)\n",
    "    openai_response = openai_generation(topic)\n",
    "\n",
    "    # Generate embeddings for the user input\n",
    "    embedding_response = gemini_embedding_generation(user_input)\n",
    "    embedding_response_OAI = gemini_embedding_generation(openai_response)\n",
    "    embedding_response_GEMINI = gemini_embedding_generation(gemini_response)\n",
    "\n",
    "    # Generate POS types for the user input\n",
    "    pos_types = words_to_pos_types(user_input)\n",
    "    pos_types_OAI = words_to_pos_types(openai_response)\n",
    "    pos_types_GEMINI = words_to_pos_types(gemini_response)\n",
    "\n",
    "    # Create text data objects for each response\n",
    "    text_data = TextData.create_from_user_input(user_input, pos_types, embedding_response)\n",
    "    text_data_OAI = TextData.create_from_user_input(openai_response, pos_types_OAI, AI, embedding_response_OAI,\n",
    "                                                    GEMINI_MODEL_NAME)\n",
    "    text_data_GEMINI = TextData.create_from_user_input(gemini_response, pos_types_GEMINI, AI, embedding_response_GEMINI,\n",
    "                                                       OPENAI_MODEL_NAME)\n",
    "\n",
    "    return text_data, text_data_OAI, text_data_GEMINI, topic"
   ],
   "id": "9d72cf6344325548",
   "execution_count": 5,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-01T22:29:43.090302Z",
     "start_time": "2025-04-01T22:29:43.087111Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def classify_text(text_data: TextData, k_mean_model: KMeanModel, hierarchical_model: HierarchicalModel,\n",
    "                  h_autoencoder: AutoencoderModel, AI_autoencoder: AutoencoderModel,\n",
    "                  human_transition_matrix, ai_transition_matrix):\n",
    "    \"\"\"\n",
    "    Classify the text data using KMeans, Hierarchical clustering, and Autoencoders.\n",
    "    \"\"\"\n",
    "    # KMeans Classification\n",
    "    k_mean_classification = k_mean_cluster_fit_predict(k_mean_model.model, text_data, EMBEDDING_CLASSIFICATION,\n",
    "                                                       k_mean_model.feature_array)\n",
    "    # Hierarchical Classification\n",
    "    hierarchical_classification = hierarchical_cluster_fit_predict(hierarchical_model.agg_cluster,\n",
    "                                                                   text_data,\n",
    "                                                                   EMBEDDING_CLASSIFICATION,\n",
    "                                                                   hierarchical_model.cluster_majority,\n",
    "                                                                   hierarchical_model.cluster_centroid)\n",
    "\n",
    "    # Autoencoder Classification\n",
    "    autoencoder_classification = autoencoder_classify_text(text_data.embedding_classification, h_autoencoder.encoder,\n",
    "                                                           AI_autoencoder.encoder, h_autoencoder.criterion,\n",
    "                                                           AI_autoencoder.criterion, )\n",
    "\n",
    "    ai_transition_probability = evaluate_sequence(text_data.pos_transition_matrix, ai_transition_matrix)\n",
    "    human_transition_probability = evaluate_sequence(text_data.pos_transition_matrix, human_transition_matrix)\n",
    "    # if the human_transition_probability is greater than the ai_transition_probability, then the text is classified\n",
    "    # as human\n",
    "    if human_transition_probability > ai_transition_probability:\n",
    "        transition_classification = HUMAN\n",
    "    else:\n",
    "        transition_classification = AI\n",
    "\n",
    "    # Find the classification based on the vote\n",
    "    classification = text_data.classify_with_vote(k_mean_classification, hierarchical_classification,\n",
    "                                                  autoencoder_classification, transition_classification)\n",
    "\n",
    "    return classification, k_mean_classification, hierarchical_classification, autoencoder_classification, \\\n",
    "        transition_classification"
   ],
   "id": "6df4d5af3a415504",
   "execution_count": 6,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-01T22:29:43.264530Z",
     "start_time": "2025-04-01T22:29:43.261122Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def main(user_input_file_path: str = None):\n",
    "    \"\"\"\n",
    "    Main function to load models, handle user input, and classify text.\n",
    "    \"\"\"\n",
    "    # Load models\n",
    "    kmeans_model, hierarchical_model, h_autoencoder, AI_autoencoder, human_transition_matrix, ai_transition_matrix = \\\n",
    "        load_models(k_mean_file_path, hierarchical_file_path, autoencoder_file_path,\n",
    "                    human_transition_matrix_file_path, ai_transition_matrix_file_path)\n",
    "\n",
    "    # Read user input for file\n",
    "    if user_input_file_path is None:\n",
    "         user_input = None  \n",
    "    else:\n",
    "        with open(user_input_file_path, 'r') as file:\n",
    "            # read the file content\n",
    "            user_input = file.read()\n",
    "    text_data, text_data_OAI, text_data_GEMINI, topic = handle_user_input(user_input=user_input)\n",
    "\n",
    "    # Classify text data\n",
    "    classification, k_mean_classification, hierarchical_classification, autoencoder_classification, \\\n",
    "        transition_classification = classify_text(text_data, kmeans_model, hierarchical_model,\n",
    "                                                  h_autoencoder, AI_autoencoder,\n",
    "                                                  human_transition_matrix, ai_transition_matrix)\n",
    "\n",
    "    print(f\"Classification: {classification}\")\n",
    "    print(f\"KMeans Classification: {k_mean_classification}\")\n",
    "    print(f\"Hierarchical Classification: {hierarchical_classification}\")\n",
    "    print(f\"Autoencoder Classification: {autoencoder_classification}\")\n",
    "    print(f\"Transition Classification: {transition_classification}\")"
   ],
   "id": "a614f46a4889dfcb",
   "execution_count": 7,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-01T22:30:18.235085Z",
     "start_time": "2025-04-01T22:29:43.432762Z"
    }
   },
   "cell_type": "code",
   "source": [
    "main(\"./test.txt\")\n",
    "    "
   ],
   "id": "154eef4c236c3e5e",
   "execution_count": 8,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "c5add2f1b92427c8",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "execution_count": null,
   "source": "",
   "id": "7cf4e17196856196",
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
