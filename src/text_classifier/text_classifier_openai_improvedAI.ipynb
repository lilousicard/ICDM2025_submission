{
 "cells": [
  {
   "cell_type": "code",
   "id": "d2dc5c315282de4f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-03T21:05:46.599128Z",
     "start_time": "2025-04-03T21:05:46.450424Z"
    }
   },
   "source": [
    "import sys\n",
    "import os\n",
    "project_path = os.path.abspath('/Enter/Your/Project/Path/Here/')\n",
    "sys.path.append(project_path)\n",
    "from src.API.mongo_utils import get_mongo_client, get_collection\n",
    "from src.API.constant import AI, HUMAN, REUTER_COLLECTION, OPEN_AI_IMPROVED_COLLECTION\n",
    "\n",
    "# IMPORTANT: 0 is AI, 1 is Human\n",
    "# Initialize the client\n",
    "client = get_mongo_client()\n",
    "# Fetch collections\n",
    "human_collection = get_collection(REUTER_COLLECTION)\n",
    " \n",
    "improved_ai_collection = get_collection(OPEN_AI_IMPROVED_COLLECTION)\n",
    "\n",
    "# Fetch documents from the collections\n",
    "human_documents = human_collection.find()\n",
    "improved_ai_documents = improved_ai_collection.find()"
   ],
   "execution_count": 1,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "af74b2b1e2a1f06b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-03T21:05:46.601357Z",
     "start_time": "2025-04-03T21:05:46.600005Z"
    }
   },
   "source": [
    "# Constant for the field names\n",
    "EMBEDDING_CLUSTERS = 'embedding_clustering'\n",
    "EMBEDDING_CLASSIFICATION = 'embedding_classification'"
   ],
   "execution_count": 2,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "c76df46fed82d195",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-03T21:06:23.883267Z",
     "start_time": "2025-04-03T21:05:46.601796Z"
    }
   },
   "source": [
    "from src.API.text_classifier import create_text_data_list\n",
    "# print update\n",
    "print(\"Starting to create text data list\")\n",
    "\n",
    "# Create a list of TextData objects\n",
    "print(\"Creating text data list for AI\")\n",
    "# OpenAI Improved: 84% accuracy\n",
    "# Improved Gemini: 83% accuracy\n",
    "AI_texts = create_text_data_list(improved_ai_documents, AI)\n",
    "print(\"Creating text data list for Human\")\n",
    "human_texts = create_text_data_list(human_documents, HUMAN)\n",
    "# Shuffle AI_texts\n",
    "import random\n",
    "random.shuffle(AI_texts)\n",
    "AI_texts = AI_texts[:5000]"
   ],
   "execution_count": 3,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "bfc72753bf85b774",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-03T21:06:23.885531Z",
     "start_time": "2025-04-03T21:06:23.883919Z"
    }
   },
   "source": [
    "print(len(AI_texts))\n",
    "print(len(human_texts))"
   ],
   "execution_count": 4,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "fc3547ca89efddd6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-03T21:06:24.437721Z",
     "start_time": "2025-04-03T21:06:23.886855Z"
    }
   },
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the list into training and testing\n",
    "AI_train, AI_test = train_test_split(AI_texts, test_size=0.2, random_state=42)\n",
    "human_train, human_test = train_test_split(human_texts, test_size=0.2, random_state=42)\n",
    "training_data = AI_train + human_train\n",
    "test_data = AI_test + human_test"
   ],
   "execution_count": 5,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "2e80562370cd7a4b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-03T21:06:24.439761Z",
     "start_time": "2025-04-03T21:06:24.438327Z"
    }
   },
   "source": [
    "# Print the length of the training and testing data\n",
    "print(\"Training data length: \", len(training_data))\n",
    "print(\"Testing data length: \", len(test_data))"
   ],
   "execution_count": 6,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "adc2fb54b78de82e",
   "metadata": {},
   "source": [
    "# **K-Mean Clustering**"
   ]
  },
  {
   "cell_type": "code",
   "id": "a83b183e727503cf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-03T21:06:25.548691Z",
     "start_time": "2025-04-03T21:06:24.440182Z"
    }
   },
   "source": [
    "from src.API.machine_learning import k_mean_cluster\n",
    "\n",
    "n_clusters = 4\n",
    "# Train the KMeans model\n",
    "print(\"Training the KMeans model with classification embeddings\")\n",
    "classification_kmeans, classification_feature_array, classification_cluster_majorities = k_mean_cluster(training_data, EMBEDDING_CLASSIFICATION, 'text_type', n_clusters)"
   ],
   "execution_count": 7,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "9e59c200f681b0ed",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-03T21:06:25.551510Z",
     "start_time": "2025-04-03T21:06:25.549633Z"
    }
   },
   "source": [
    "# print the vote dictionary for the first text data\n",
    "print(training_data[0].votes)\n",
    "print(training_data[0].text_type)"
   ],
   "execution_count": 8,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "3e6b918973a63f29",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-03T21:06:25.714763Z",
     "start_time": "2025-04-03T21:06:25.552136Z"
    }
   },
   "source": [
    "from src.API.machine_learning import plot_latest_result, plot_actual_label, plot_actual_label_3d\n",
    "%matplotlib notebook\n",
    "# Print update\n",
    "print(\"Visualizing the result\")\n",
    "# Visualize the result\n",
    "plot_latest_result(training_data, 'KMeans2_embedding_classification', 'embedding_classification')\n",
    "plot_actual_label(training_data, 'embedding_classification')\n",
    "plot_actual_label_3d(training_data, 'embedding_classification')"
   ],
   "execution_count": 9,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "ec13d927a2ea86e4",
   "metadata": {
    "scrolled": true,
    "ExecuteTime": {
     "end_time": "2025-04-03T21:06:48.639498Z",
     "start_time": "2025-04-03T21:06:48.626212Z"
    }
   },
   "source": [
    "from src.API.machine_learning import generate_classification_report\n",
    "\n",
    "\n",
    "def calculate_accuracy_and_generate_report(data_list):\n",
    "    \"\"\"\n",
    "    Calculate accuracy based on text_data votes and generate a classification report.\n",
    "    \n",
    "    :param data_list: List of text_data objects. Each must have a `classify()` method and a `text_type` attribute.\n",
    "    \"\"\"\n",
    "    if data_list is None or len(data_list) == 0:\n",
    "        print(\"The data list is empty\")\n",
    "        return\n",
    "\n",
    "    true_labels = []\n",
    "    predicted_labels = []\n",
    "    correct = 0\n",
    "\n",
    "    for text_data in data_list:\n",
    "        pred = text_data.classify()\n",
    "        true = text_data.text_type\n",
    "        predicted_labels.append(pred)\n",
    "        true_labels.append(true)\n",
    "        if pred == true:\n",
    "            correct += 1\n",
    "\n",
    "    accuracy = correct / len(data_list)\n",
    "    print(f\"Accuracy: {accuracy}\")\n",
    "\n",
    "    generate_classification_report(true_labels, predicted_labels, target_names=[\"AI\", \"HUMAN\"])\n",
    "\n",
    "\n",
    "calculate_accuracy_and_generate_report(training_data)"
   ],
   "execution_count": 10,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "8edd9e4882cb4ad1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-03T21:07:12.761932Z",
     "start_time": "2025-04-03T21:07:12.727941Z"
    }
   },
   "source": [
    "from src.API.machine_learning import k_mean_cluster_test\n",
    "\n",
    "# Test the model\n",
    "print(\"Testing the model\")\n",
    "\n",
    "result_array, cluster_label = k_mean_cluster_test(classification_kmeans, test_data, EMBEDDING_CLASSIFICATION, 'text_type', classification_cluster_majorities)\n",
    "#result_array, cluster_label = k_mean_cluster_test(small_kmeans, test_data, EMBEDDING_SMALL, 'text_type', small_cluster_majorities)\n",
    "\n",
    "# Visualize the result\n",
    "plot_latest_result(test_data,'KMeans2_embedding_classification', EMBEDDING_CLASSIFICATION)\n",
    "plot_actual_label(test_data, EMBEDDING_CLASSIFICATION)\n",
    "plot_actual_label_3d(test_data, EMBEDDING_CLASSIFICATION)\n",
    "# Calculate the accuracy using the vote\n",
    "calculate_accuracy_and_generate_report(test_data)"
   ],
   "execution_count": 11,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-03T21:07:12.767577Z",
     "start_time": "2025-04-03T21:07:12.765720Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Save the model \n",
    "from src.API.machine_learning import save_kmeans_model\n",
    "save_kmeans_model(classification_kmeans, EMBEDDING_CLASSIFICATION, classification_cluster_majorities, \"kmean.pkl\")"
   ],
   "id": "6421c8696cccfe1d",
   "execution_count": 12,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "1593a4e1f9e389f8",
   "metadata": {},
   "source": [
    "# **Hierarchical Clustering**"
   ]
  },
  {
   "cell_type": "code",
   "id": "3b3a7e4753243dd0",
   "metadata": {
    "scrolled": true,
    "ExecuteTime": {
     "end_time": "2025-04-03T21:07:15.096573Z",
     "start_time": "2025-04-03T21:07:12.768444Z"
    }
   },
   "source": [
    "from src.API.machine_learning import hierarchical_cluster, hierarchical_cluster_test\n",
    "\n",
    "n_clusters = 4\n",
    "distance_threshold = 0.75\n",
    "# Train the Hierarchical model\n",
    "print(\"Training the Hierarchical model\")\n",
    "hierarchical_model, hierarchical_feature_array, hierarchical_cluster_majorities, hierarchical_centroids = hierarchical_cluster(training_data, EMBEDDING_CLASSIFICATION, 'text_type', n_clusters, distance_threshold)\n",
    "\n",
    "\n",
    "# Test the model\n",
    "print(\"Testing the Hierarchical model\")\n",
    "result_array, cluster_label = hierarchical_cluster_test(hierarchical_model, test_data, EMBEDDING_CLASSIFICATION, 'text_type', hierarchical_cluster_majorities, hierarchical_centroids)\n",
    "\n",
    "# Calculate the accuracy using the vote\n",
    "calculate_accuracy_and_generate_report(test_data)\n",
    "print(test_data[0].votes)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ],
   "execution_count": 13,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-03T21:07:15.100751Z",
     "start_time": "2025-04-03T21:07:15.097548Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Save the hierarchical model \n",
    "from src.API.machine_learning import save_hierarchical_model\n",
    "save_hierarchical_model(hierarchical_model, EMBEDDING_CLASSIFICATION, hierarchical_cluster_majorities, hierarchical_centroids, \"hierarchical.pkl\")"
   ],
   "id": "4ee48dd7aef83170",
   "execution_count": 14,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "48373abc36dab7ec",
   "metadata": {},
   "source": [
    "**Auto-Encoder**"
   ]
  },
  {
   "cell_type": "code",
   "id": "5d2ad5037401a631",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-03T21:07:15.154197Z",
     "start_time": "2025-04-03T21:07:15.101360Z"
    }
   },
   "source": [
    "# Create the dataloader\n",
    "from src.API.machine_learning import create_dataloader\n",
    "field = EMBEDDING_CLASSIFICATION \n",
    "human_dataloader = create_dataloader(human_train, field, 64)\n",
    "AI_dataloader = create_dataloader(AI_train, field, 64)"
   ],
   "execution_count": 15,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "4c53406906c4a5fc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-03T21:07:15.633053Z",
     "start_time": "2025-04-03T21:07:15.155173Z"
    }
   },
   "source": [
    "# Initialize the model\n",
    "# fetch the field size using the field variable\n",
    "input_dim = len(getattr(human_texts[0], field))  # Size of the embeddings\n",
    "print(input_dim)\n",
    "latent_dim = 128  # Dimensionality of the latent space\n",
    "\n",
    "# Create 2 encoders\n",
    "from src.API.machine_learning import create_autoencoder\n",
    "h_encoder, h_criterion, h_optimizer = create_autoencoder(input_dim, latent_dim, 0.001)\n",
    "AI_encoder, AI_criterion, AI_optimizer = create_autoencoder(input_dim, latent_dim, 0.001)"
   ],
   "execution_count": 16,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "5ffd2befebaa595b",
   "metadata": {
    "scrolled": true,
    "ExecuteTime": {
     "end_time": "2025-04-03T21:07:18.746250Z",
     "start_time": "2025-04-03T21:07:15.633623Z"
    }
   },
   "source": [
    "# Train human encoder\n",
    "from src.API.machine_learning import train_autoencoder\n",
    "print(\"Training human encoder\")\n",
    "train_autoencoder(h_encoder, h_criterion, h_optimizer, human_dataloader, 20)\n",
    "\n",
    "# Train AI encoder\n",
    "print(\"Training AI encoder\")\n",
    "train_autoencoder(AI_encoder, AI_criterion, AI_optimizer, AI_dataloader, 20)"
   ],
   "execution_count": 17,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "c378d919320b723b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-03T21:07:18.749515Z",
     "start_time": "2025-04-03T21:07:18.746913Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "# Test the encoder\n",
    "encoder_test_set = np.concatenate((human_test, AI_test))\n",
    "\n",
    "# Create a list x that contains the embeddings and a list y that contains the labels\n",
    "x = []\n",
    "y = []\n",
    "for text_data in encoder_test_set:\n",
    "    x.append(getattr(text_data, field))\n",
    "    y.append(text_data.text_type)"
   ],
   "execution_count": 18,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "1e0cf07522a8a4ee",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-03T21:07:18.765018Z",
     "start_time": "2025-04-03T21:07:18.750273Z"
    }
   },
   "source": [
    "import torch\n",
    "# Convert the test data to tensor\n",
    "X_test_tensor = torch.tensor(x, dtype=torch.float32)"
   ],
   "execution_count": 19,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "a8656a6fee456a0b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-03T21:07:18.959226Z",
     "start_time": "2025-04-03T21:07:18.765592Z"
    }
   },
   "source": [
    "# Evaluate each test embedding\n",
    "method_name = \"Auto-Encoder\"+\"_\"+field\n",
    "predictions = []\n",
    "with torch.no_grad():\n",
    "    for idx, embedding in enumerate(X_test_tensor):\n",
    "        # Get reconstruction errors\n",
    "        reconstructed_human = h_encoder(embedding)\n",
    "        error_human = h_criterion(reconstructed_human, embedding).item()\n",
    "        \n",
    "        reconstructed_ai = AI_encoder(embedding)\n",
    "        error_ai = AI_criterion(reconstructed_ai, embedding).item()\n",
    "        \n",
    "        # Classify based on reconstruction error\n",
    "        if error_human < error_ai:\n",
    "            classification = HUMAN  # Classified as Human-written\n",
    "            predictions.append(HUMAN)\n",
    "        else:\n",
    "            classification = AI  # Classified as AI-generated\n",
    "            predictions.append(AI)\n",
    "        # Add the vote\n",
    "        encoder_test_set[idx].add_vote(method_name, classification)"
   ],
   "execution_count": 20,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "10ac072bf2590b33",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-03T21:07:18.967883Z",
     "start_time": "2025-04-03T21:07:18.959943Z"
    }
   },
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Calculate the accuracy using the vote\n",
    "calculate_accuracy_and_generate_report(encoder_test_set)\n",
    "# Convert predictions to a NumPy array\n",
    "predictions = np.array(predictions)\n",
    "\n",
    "# Print evaluation metrics\n",
    "print(classification_report(y, predictions, target_names=[\"Human\", \"AI\"]))"
   ],
   "execution_count": 21,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "c4d7e03a1c222f12",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-03T21:07:19.010079Z",
     "start_time": "2025-04-03T21:07:18.969500Z"
    }
   },
   "source": [
    "# Visualize the result\n",
    "print(\"method_name: \"+method_name+ \" field: \"+field)\n",
    "plot_latest_result(encoder_test_set, method_name, field)\n",
    "plot_actual_label(encoder_test_set, field)"
   ],
   "execution_count": 22,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "ccb79bede8e5ea94",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-03T21:07:19.012047Z",
     "start_time": "2025-04-03T21:07:19.010629Z"
    }
   },
   "source": [
    "def is_wrongly_classified(text_data):\n",
    "    return text_data.classify() != text_data.text_type"
   ],
   "execution_count": 23,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "9a2eea317a74fcaf",
   "metadata": {
    "scrolled": true,
    "ExecuteTime": {
     "end_time": "2025-04-03T21:07:19.023304Z",
     "start_time": "2025-04-03T21:07:19.012564Z"
    }
   },
   "source": [
    "inaccurate = 0\n",
    "for text_data in encoder_test_set:\n",
    "    if is_wrongly_classified(text_data):\n",
    "        print('*'*50)\n",
    "        inaccurate += 1\n",
    "        print(text_data.id)\n",
    "        print(text_data.text_type)\n",
    "        print(text_data.votes)\n",
    "        print('*'*50)\n",
    "print(inaccurate)"
   ],
   "execution_count": 24,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-03T21:07:19.046831Z",
     "start_time": "2025-04-03T21:07:19.023939Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Save Auto-Encoders\n",
    "from src.API.machine_learning import save_autoencoders\n",
    "save_autoencoders(h_encoder, AI_encoder, h_optimizer, AI_optimizer, input_dim, latent_dim, filename=\"autoencoders.pth\")"
   ],
   "id": "4117a12dac624cb7",
   "execution_count": 25,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "a5159697a25dbb76",
   "metadata": {},
   "source": [
    "**Simple POS Transition Matrix**"
   ]
  },
  {
   "cell_type": "code",
   "id": "66144e856e74183",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-03T21:07:19.064420Z",
     "start_time": "2025-04-03T21:07:19.047378Z"
    }
   },
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ],
   "execution_count": 26,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "a22ebfda28abd1a6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-03T21:07:20.167643Z",
     "start_time": "2025-04-03T21:07:19.065288Z"
    }
   },
   "source": [
    "from src.API.machine_learning import compute_transition_matrix, evaluate_sequence\n",
    "\n",
    "# Create mappings from pos_tags (as tuples) to text_data objects\n",
    "human_pos_to_text_data = {tuple(text_data.pos_tags): text_data for text_data in human_train + human_test}\n",
    "AI_pos_to_text_data = {tuple(text_data.pos_tags): text_data for text_data in AI_train + AI_test}\n",
    "\n",
    "\n",
    "# fetch the attribute pos_tags for all the text_data objects\n",
    "human_train_pos = [text_data.pos_tags for text_data in human_train]\n",
    "AI_train_pos = [text_data.pos_tags for text_data in AI_train]\n",
    "human_test_pos = [text_data.pos_tags for text_data in human_test]\n",
    "AI_test_pos = [text_data.pos_tags for text_data in AI_test]\n",
    "\n",
    "# Compute the transition matrix\n",
    "human_transition_matrix = compute_transition_matrix(human_train_pos)\n",
    "AI_transition_matrix = compute_transition_matrix(AI_train_pos)\n",
    "\n",
    "# Evaluate the test sequences using the transition matrices\n",
    "human_normalized_log_likelihoods = [evaluate_sequence(seq, human_transition_matrix) for seq in human_test_pos]\n",
    "human_Ai_normalized_log_likelihoods = [evaluate_sequence(seq, AI_transition_matrix) for seq in human_test_pos]\n",
    "AI_normalized_log_likelihoods = [evaluate_sequence(seq, AI_transition_matrix) for seq in AI_test_pos]\n",
    "Ai_human_normalized_log_likelihoods = [evaluate_sequence(seq, human_transition_matrix) for seq in AI_test_pos]\n"
   ],
   "execution_count": 27,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "db5e7de7d136e5e1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-03T21:07:20.182279Z",
     "start_time": "2025-04-03T21:07:20.168163Z"
    }
   },
   "source": [
    "# Compare human test sequences\n",
    "human_comparisons = [\n",
    "    (human_ll, ai_ll, HUMAN if human_ll > ai_ll else AI)\n",
    "    for human_ll, ai_ll in zip(human_normalized_log_likelihoods, human_Ai_normalized_log_likelihoods)\n",
    "]\n",
    "\n",
    "# Compare AI test sequences\n",
    "ai_comparisons = [\n",
    "    (ai_ll, human_ll, AI if ai_ll > human_ll else HUMAN)\n",
    "    for ai_ll, human_ll in zip(AI_normalized_log_likelihoods, Ai_human_normalized_log_likelihoods)\n",
    "]"
   ],
   "execution_count": 28,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "e2b8a1f507d23c9a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-03T21:07:20.201432Z",
     "start_time": "2025-04-03T21:07:20.182752Z"
    }
   },
   "source": [
    "# Assign votes to human test text data\n",
    "method_name = \"Simple_POS_Transition_Matrix\"\n",
    "for pos_tags, (human_ll, ai_ll, vote) in zip(human_test_pos, human_comparisons):\n",
    "    text_data = human_pos_to_text_data[tuple(pos_tags)]\n",
    "    text_data.add_vote(method_name, vote)\n",
    "\n",
    "# Assign votes to AI test text data\n",
    "for pos_tags, (ai_ll, human_ll, vote) in zip(AI_test_pos, ai_comparisons):\n",
    "    text_data = AI_pos_to_text_data[tuple(pos_tags)]\n",
    "    text_data.add_vote(method_name, vote)\n"
   ],
   "execution_count": 29,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "5d2bb4ee98b24092",
   "metadata": {
    "scrolled": true,
    "ExecuteTime": {
     "end_time": "2025-04-03T21:07:20.220125Z",
     "start_time": "2025-04-03T21:07:20.201916Z"
    }
   },
   "source": [
    "inaccurate = 0\n",
    "for text_data in encoder_test_set:\n",
    "    if is_wrongly_classified(text_data):\n",
    "        print('*'*50)\n",
    "        inaccurate += 1\n",
    "        print(text_data.id)\n",
    "        print(text_data.votes)\n",
    "print(\"Inaccurate = \" + str(inaccurate))\n",
    "# Calculate the accuracy using the vote\n",
    "calculate_accuracy_and_generate_report(encoder_test_set)"
   ],
   "execution_count": 30,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "6695313b711f7f51",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-03T21:07:20.234118Z",
     "start_time": "2025-04-03T21:07:20.220640Z"
    }
   },
   "source": [
    "# Calculate the accuracy of the predictions making sure to use float division\n",
    "human_accuracy = sum(1.0 for _, _, predicted in human_comparisons if predicted == HUMAN) / len(human_comparisons)\n",
    "ai_accuracy = sum(1.0 for _, _, predicted in ai_comparisons if predicted == AI) / len(ai_comparisons)\n",
    "\n",
    "# Calculate the number of times human is predicted as AI and vice versa\n",
    "human_accuracy_wrong = sum(1 for _, _, predicted in human_comparisons if predicted == AI)\n",
    "ai_accuracy_wrong = sum(1 for _, _, predicted in ai_comparisons if predicted == HUMAN)"
   ],
   "execution_count": 31,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "38c9d63e61cb6b07",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-03T21:07:20.247740Z",
     "start_time": "2025-04-03T21:07:20.234695Z"
    }
   },
   "source": [
    "# Print the results\n",
    "print(\"Human accuracy:\", human_accuracy)\n",
    "print(\"AI accuracy:\", ai_accuracy)\n",
    "print(\"Number of time Human is predicted as AI:\", human_accuracy_wrong)\n",
    "print(\"Number of time AI is predicted as Human:\", ai_accuracy_wrong)"
   ],
   "execution_count": 32,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "159c4f7d1a45453f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-03T21:07:20.263014Z",
     "start_time": "2025-04-03T21:07:20.248235Z"
    }
   },
   "source": [
    "# Compute the confusion matrix components\n",
    "TP_human = sum(1 for _, _, predicted in human_comparisons if predicted == HUMAN)  # Correctly predicted as Human\n",
    "FN_human = sum(1 for _, _, predicted in human_comparisons if predicted == AI)     # Incorrectly predicted as AI\n",
    "\n",
    "TP_ai = sum(1 for _, _, predicted in ai_comparisons if predicted == AI)          # Correctly predicted as AI\n",
    "FN_ai = sum(1 for _, _, predicted in ai_comparisons if predicted == HUMAN)       # Incorrectly predicted as Human\n",
    "\n",
    "FP_human = FN_ai  # AI misclassified as Human\n",
    "FP_ai = FN_human  # Human misclassified as AI\n",
    "\n",
    "# Calculate Precision\n",
    "precision_human = TP_human / (TP_human + FP_human) if (TP_human + FP_human) > 0 else 0\n",
    "precision_ai = TP_ai / (TP_ai + FP_ai) if (TP_ai + FP_ai) > 0 else 0\n",
    "\n",
    "# Calculate Recall\n",
    "recall_human = TP_human / (TP_human + FN_human) if (TP_human + FN_human) > 0 else 0\n",
    "recall_ai = TP_ai / (TP_ai + FN_ai) if (TP_ai + FN_ai) > 0 else 0\n",
    "\n",
    "# Calculate F1-score\n",
    "f1_human = 2 * (precision_human * recall_human) / (precision_human + recall_human) if (precision_human + recall_human) > 0 else 0\n",
    "f1_ai = 2 * (precision_ai * recall_ai) / (precision_ai + recall_ai) if (precision_ai + recall_ai) > 0 else 0\n",
    "\n",
    "# Calculate Overall Accuracy\n",
    "total_samples = len(human_comparisons) + len(ai_comparisons)\n",
    "accuracy = (TP_human + TP_ai) / total_samples if total_samples > 0 else 0\n",
    "\n",
    "# Display results\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision (Human): {precision_human:.4f}\")\n",
    "print(f\"Recall (Human): {recall_human:.4f}\")\n",
    "print(f\"F1-score (Human): {f1_human:.4f}\")\n",
    "print(f\"Precision (AI): {precision_ai:.4f}\")\n",
    "print(f\"Recall (AI): {recall_ai:.4f}\")\n",
    "print(f\"F1-score (AI): {f1_ai:.4f}\")"
   ],
   "execution_count": 33,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-03T21:07:20.276662Z",
     "start_time": "2025-04-03T21:07:20.263604Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Save POS Matrix\n",
    "from src.API.machine_learning import save_transition_matrix\n",
    "save_transition_matrix(human_transition_matrix, \"human_matrix.pkl\")\n",
    "save_transition_matrix(AI_transition_matrix, \"AI_matrix.pkl\")"
   ],
   "id": "a3d9d06da114218a",
   "execution_count": 34,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "be698da227714e87",
   "metadata": {
    "scrolled": true,
    "ExecuteTime": {
     "end_time": "2025-04-03T21:07:20.293685Z",
     "start_time": "2025-04-03T21:07:20.277118Z"
    }
   },
   "source": [
    "calculate_accuracy_and_generate_report(test_data)"
   ],
   "execution_count": 35,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "c6f747122c4c146d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-03T21:07:20.295646Z",
     "start_time": "2025-04-03T21:07:20.294391Z"
    }
   },
   "source": [],
   "execution_count": 35,
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
